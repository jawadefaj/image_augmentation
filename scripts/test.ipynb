{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configuration as cfg\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import copy\n",
    "import albumentations as A\n",
    "import random\n",
    "\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "color_dict = {\n",
    "    'person': (255, 0, 0), # red \n",
    "    'people': (0, 255, 0), # green\n",
    "    'cyclist':(0, 0, 255), # blue\n",
    "}\n",
    "\n",
    "\n",
    "def GaussianBlur(rgb_img, ir_img, box, kernel=(5, 55)):\n",
    "    rgb_after = cv2.GaussianBlur(rgb_img, kernel, 0)\n",
    "    ir_after = cv2.GaussianBlur(ir_img, kernel, 0)\n",
    "    return rgb_after, ir_after, box \n",
    "\n",
    "#  [0, 1]\n",
    "def GaussianNoise(rgb_img, ir_img, box):\n",
    "    row,col,ch= rgb_img.shape\n",
    "    mean = 0\n",
    "    var = 0.01\n",
    "    sigma = var**0.5\n",
    "    gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "    gauss = gauss.reshape(row,col,ch)\n",
    "\n",
    "    normalized_rgb = cv2.normalize(rgb_img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    normalized_ir = cv2.normalize(ir_img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    rgb_after = np.add(normalized_rgb, gauss) * 255\n",
    "    ir_after = np.add(normalized_ir, gauss) * 255\n",
    "\n",
    "    # print('shape rgb before after ', rgb_img.shape, rgb_after.shape)\n",
    "    # print('type ', type(gauss), type(rgb_img), type(rgb_after))\n",
    "    # print('gauss ', gauss[12][0])\n",
    "    # print('rgb ', normalized_rgb[12][0])\n",
    "    # print('rgb after ', rgb_after[12][0])\n",
    "\n",
    "    return rgb_after, ir_after, box\n",
    "\n",
    "\n",
    "\n",
    "def ColorJittering(rgb_img, ir_img, box, color_aug_tuple=('hue', 0.3)):\n",
    "\n",
    "    if color_aug_tuple[0] == 'brightness':\n",
    "        color_transform = transforms.ColorJitter(brightness=color_aug_tuple[1])\n",
    "    elif color_aug_tuple[0] == 'contrast':\n",
    "        color_transform = transforms.ColorJitter(contrast=color_aug_tuple[1])\n",
    "    elif color_aug_tuple[0] == 'saturation':\n",
    "        color_transform = transforms.ColorJitter(saturation=color_aug_tuple[1])\n",
    "    elif color_aug_tuple[0] == 'hue':\n",
    "        color_transform = transforms.ColorJitter(hue=color_aug_tuple[1])\n",
    "    else:\n",
    "        raise('need a valid option')\n",
    "\n",
    "    rgb_pil_format = Image.fromarray(rgb_img)\n",
    "    ir_pil_format = Image.fromarray(ir_img)\n",
    "\n",
    "    rgb_pil_format = color_transform(rgb_pil_format)\n",
    "    ir_pil_format = color_transform(ir_pil_format)\n",
    "\n",
    "    rgb_after = np.asarray(rgb_pil_format)\n",
    "    ir_after = np.asarray(ir_pil_format)\n",
    "\n",
    "    return rgb_after, ir_after, box\n",
    "\n",
    "def HorizontalFlip(rgb_img, ir_img, bboxes):\n",
    "\n",
    "    rgb_after = cv2.flip(rgb_img, 1)\n",
    "    ir_after = cv2.flip(ir_img, 1)\n",
    "\n",
    "    img_center = np.array(rgb_img.shape[:2])[::-1]//2\n",
    "    img_center = np.hstack((img_center, img_center))\n",
    "    bboxes[:,[0,2]] += 2*(img_center[[0,2]] - bboxes[:,[0,2]])\n",
    "    box_w = abs(bboxes[:,0] - bboxes[:,2])\n",
    "    bboxes[:,0] -= box_w\n",
    "    bboxes[:,2] += box_w\n",
    "    \n",
    "    return rgb_after, ir_after, bboxes \n",
    "    \n",
    "\n",
    "class Data_Process():\n",
    "    def __init__(self, annotation_path, augmenation=None):\n",
    "        super(Data_Process,self).__init__()\n",
    "        self.annotation_path = annotation_path  \n",
    "        self.augmenation = augmenation\n",
    "        # print(augmenation)\n",
    "\n",
    "    def show_image(self, image1, image2, image3, image4):\n",
    "        f, axarr = plt.subplots(1,4, figsize=(32, 40))\n",
    "        axarr[0].imshow(image1)\n",
    "        axarr[1].imshow(image2)\n",
    "        axarr[2].imshow(image3)\n",
    "        axarr[3].imshow(image4)\n",
    "        plt.title('data')\n",
    "        plt.show()\n",
    "        pass\n",
    "    \n",
    "    def pre_process_img(self):\n",
    "        for annot_file_name in os.listdir(self.annotation_path):\n",
    "            file_id = annot_file_name.split('.txt')[0]\n",
    "            annot_file = os.path.join(self.annotation_path, annot_file_name)\n",
    "            rgb_img_path = os.path.join(cfg.rgb_imgs, file_id+'.png')\n",
    "            ir_img_path = os.path.join(cfg.ir_imgs, file_id+'.png')\n",
    "            rgb_img = cv2.imread(rgb_img_path)\n",
    "            ir_img = cv2.imread(ir_img_path)\n",
    "            # print(rgb_img.shape, ir_img.shape)\n",
    "            \n",
    "            rgb_before = copy.deepcopy(rgb_img)\n",
    "            ir_before = copy.deepcopy(ir_img)\n",
    "\n",
    "            # Read File\n",
    "            with open(annot_file, 'r') as f:\n",
    "                objs = f.readlines()[1:]\n",
    "            boxes = []\n",
    "            names = []\n",
    "            for ix, obj in enumerate(objs):\n",
    "                obj_split = obj.split(' ')\n",
    "                #obj_count += 1\n",
    "                name = str(obj_split[0])\n",
    "                x1 = int(obj_split[1])\n",
    "                y1 = int(obj_split[2])\n",
    "                x2 = x1 + int(obj_split[3])\n",
    "                y2 = y1 + int(obj_split[4])\n",
    "                boxes.append([x1, y1, x2, y2, name])\n",
    "                # names.append(name)\n",
    "\n",
    "            boxes = np.asarray(boxes)\n",
    "            boxes_before = copy.deepcopy(boxes)\n",
    "            print(\"annotations: \",boxes, boxes.shape)\n",
    "\n",
    "\n",
    "            ######Augmentation implementation\n",
    "            aug_rgb_img, aug_ir_img, updated_boxes = self.augmenation(rgb_before, ir_before, boxes_before)\n",
    "            ################\n",
    "\n",
    "            for i in range(len(names)):\n",
    "                box = boxes[i]\n",
    "                color = color_dict[names[i]]\n",
    "                cv2.rectangle(rgb_img, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "                cv2.rectangle(ir_img, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "                \n",
    "            for i in range(len(updated_boxes)):\n",
    "                box = updated_boxes[i]\n",
    "                # color = color_dict[names[i]]\n",
    "                cv2.rectangle(aug_rgb_img, (box[0], box[1]), (box[2], box[3]), (255, 255, 255), 2)\n",
    "                cv2.rectangle(aug_ir_img, (box[0], box[1]), (box[2], box[3]), (255, 255, 255), 2)\n",
    "\n",
    "            self.show_image(rgb_img, ir_img, aug_rgb_img, aug_ir_img)\n",
    "\n",
    "            # break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations:  [['567' '232' '605' '325' 'person']\n",
      " ['176' '215' '197' '264' 'person']\n",
      " ['218' '218' '238' '261' 'person']\n",
      " ['127' '206' '151' '254' 'person']\n",
      " ['112' '205' '135' '255' 'person']] (5, 5)\n",
      "bbox [['567' '232' '605' '325' 'person']\n",
      " ['176' '215' '197' '264' 'person']\n",
      " ['218' '218' '238' '261' 'person']\n",
      " ['127' '206' '151' '254' 'person']\n",
      " ['112' '205' '135' '255' 'person']]\n",
      "bbox [['567' '232' '605' '325' 'person']\n",
      " ['176' '215' '197' '264' 'person']\n",
      " ['218' '218' '238' '261' 'person']\n",
      " ['127' '206' '151' '254' 'person']\n",
      " ['112' '205' '135' '255' 'person']]\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U11'), dtype('<U11')) -> dtype('<U11')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-01cfcbecf544>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[0mdata_process\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData_Process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotation_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugmenation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomCrop\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m###pass your augmentation object here instead of None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mdata_process\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_process_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-c5406e387074>\u001b[0m in \u001b[0;36mpre_process_img\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;31m######Augmentation implementation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m             \u001b[0maug_rgb_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maug_ir_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdated_boxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugmenation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb_before\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mir_before\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboxes_before\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m             \u001b[1;31m################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-01cfcbecf544>\u001b[0m in \u001b[0;36mRandomCrop\u001b[1;34m(rgb_img, ir_img, bboxes, ratio)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bbox'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mnew_box\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mleft_top_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_top_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom_right_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom_right_y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'new boxes '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-01cfcbecf544>\u001b[0m in \u001b[0;36mclip_box\u001b[1;34m(bbox, clip_box, alpha)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# print(bbox, clip_box, alpha)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mar_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbbox_area\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'array '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mar_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-01cfcbecf544>\u001b[0m in \u001b[0;36mbbox_area\u001b[1;34m(bbox)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bbox'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclip_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_box\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U11'), dtype('<U11')) -> dtype('<U11')"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def bbox_area(bbox):\n",
    "    print('bbox', bbox)\n",
    "\n",
    "    return (bbox[:,2] - bbox[:,0])*(bbox[:,3] - bbox[:,1])\n",
    "\n",
    "def clip_box(bbox, clip_box, alpha):\n",
    "\n",
    "    # print(bbox, clip_box, alpha)\n",
    "    ar_ = bbox_area(bbox)\n",
    "\n",
    "    print('array ', ar_)\n",
    "    x_min = np.maximum(bbox[:,0], clip_box[0]).reshape(-1,1)\n",
    "    y_min = np.maximum(bbox[:,1], clip_box[1]).reshape(-1,1)\n",
    "    x_max = np.minimum(bbox[:,2], clip_box[2]).reshape(-1,1)\n",
    "    y_max = np.minimum(bbox[:,3], clip_box[3]).reshape(-1,1)\n",
    "    \n",
    "    bbox = np.hstack((x_min, y_min, x_max, y_max, bbox[:,4:]))\n",
    "    \n",
    "    delta_area = ((ar_ - bbox_area(bbox))/ar_)\n",
    "    \n",
    "    mask = (delta_area < (1 - alpha)).astype(int)\n",
    "    \n",
    "    bbox = bbox[mask == 1,:]\n",
    "\n",
    "    return bbox\n",
    "\n",
    "def RandomCrop(rgb_img, ir_img, bboxes, ratio=0.7):\n",
    "\n",
    "    inv_ratio = 1/ratio\n",
    "    h, w, c = rgb_img.shape\n",
    "\n",
    "    start_h, start_w, c = int(h*ratio//2), int(w*ratio//2), c\n",
    "    end_h = h - start_h\n",
    "    end_w = w - start_w\n",
    "\n",
    "    center_w = random.randint(start_w, end_w)\n",
    "    center_h = random.randint(start_h, end_h)\n",
    "\n",
    "    left_top_x = center_w - start_w\n",
    "    left_top_y = center_h - start_h\n",
    "\n",
    "    bottom_right_x = center_w + start_w\n",
    "    bottom_right_y = center_h + start_h\n",
    "\n",
    "    # cv2.rectangle(cropped_image_temp, (left_top_x, left_top_y), (bottom_right_x, bottom_right_y), (255, 255, 0), 2)\n",
    "\n",
    "    cropped_image_rgb = rgb_img[left_top_y:bottom_right_y, left_top_x:bottom_right_x]\n",
    "    cropped_image_rgb = cv2.resize(cropped_image_rgb, (w, h))\n",
    "\n",
    "    cropped_image_ir = ir_img[left_top_y:bottom_right_y, left_top_x:bottom_right_x]\n",
    "    cropped_image_ir = cv2.resize(cropped_image_ir, (w, h))\n",
    "\n",
    "    print('bbox' , bboxes)\n",
    "    new_box = clip_box(bboxes, [left_top_x, left_top_y, bottom_right_x, bottom_right_y], 0.25)\n",
    "    print('new boxes ', new_box)\n",
    "\n",
    "    new_box[:, :4] -= [left_top_x, left_top_y, left_top_x, left_top_y]\n",
    "    new_box = np.asarray(new_box, dtype=np.float64)\n",
    "    new_box[:, :4] *= [inv_ratio, inv_ratio, inv_ratio, inv_ratio]\n",
    "    new_box = np.asarray(new_box, dtype=np.int64)\n",
    "    # print('new boxes after ', new_box)\n",
    "\n",
    "    return cropped_image_rgb, cropped_image_ir, new_box\n",
    "\n",
    "\n",
    "\n",
    "#  RandomCrop\n",
    "#  GaussianBlur\n",
    "#  HorizontalFlip\n",
    "#  ColorJittering\n",
    "#  GaussianBlur\n",
    "#  GaussianNoise\n",
    "\n",
    "data_process = Data_Process(cfg.annotation_path, augmenation=RandomCrop) ###pass your augmentation object here instead of None\n",
    "data_process.pre_process_img()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__==\"__main__\":\n",
    "#     ###########We need to implement augmentation class\n",
    "#     #augmentation = Augmentation()\n",
    "#     ################################\n",
    "#     data_process = Data_Process(cfg.annotation_path, augmenation=None) ###pass your augmentation object here instead of None\n",
    "#     data_process.pre_process_img()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('cse-cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d808d8653dda17e992e4544cb00058cf302ec08789cc80752ed7be2cb1dd310e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
